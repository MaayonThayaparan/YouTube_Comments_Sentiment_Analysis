# -----------------------------------------------------------------------------
# .env.example — Server configuration for Express API
# -----------------------------------------------------------------------------
# PURPOSE
#   Centralize all runtime configuration for the YouTube sentiment API server.
#   These variables are read at boot via `dotenv` and control API access,
#   throttling, CORS, and the in-memory response cache.
#
# HOW TO USE
#   1) Copy this file to `server/.env` (or the root where the server starts).
#   2) Fill in any required values (⚠️ never commit real secrets).
#   3) Restart the server after changes (env is only read at process start).
#
# SECURITY
#   - Do NOT commit `.env` to git. Keep it in `.gitignore`.
#   - If a real key ever leaked in git history, rotate it immediately.
#   - Prefer per-environment deployment secrets (e.g., Docker/CI secret stores).
# -----------------------------------------------------------------------------


# --- REQUIRED ---------------------------------------------------------------
# Google YouTube Data API v3 key used by youtube.js to fetch comments/metadata.
# Scope: read-only public data (comments, video & channel stats).
# Obtain: https://console.cloud.google.com/apis/credentials
# NOTE: Paste your own key here. Do not commit a real key to source control.
YOUTUBE_API_KEY=YOUR_YOUTUBE_API_KEY


# --- OPTIONAL: Network / Server --------------------------------------------
# Port the Express server listens on. If unset, defaults to 5177.
PORT=5177

# Polite delay (ms) between YouTube page fetches to smooth quota usage.
# Typical dev value: 200ms. Increase if you see rate-limiting.
YT_THROTTLE_MS=200


# --- OPTIONAL: CORS ---------------------------------------------------------
# CSV allow-list of origins permitted to call this API from a browser.
# - Use "*" ONLY for local development.
# - In production, specify explicit origins (protocol+host+port).
# Examples:
#   ALLOWED_ORIGINS=http://localhost:5173
#   ALLOWED_ORIGINS=https://app.example.com,https://staging.example.com
ALLOWED_ORIGINS=*


# --- OPTIONAL: Response Cache (in-memory LRU + TTL) -------------------------
# Enables a small in-memory cache for `GET /api/comments_scored` responses.
# Useful to avoid recomputing sentiment for the same (videoId, model) pair.
#
# CACHE_ENABLED
#   'true'  -> enable cache
#   anything else / unset -> disabled
#
# CACHE_MAX_ITEMS
#   Maximum number of cached entries kept (oldest evicted first).
#
# CACHE_TTL_MS
#   Time-to-live per entry in milliseconds. After TTL, entries are dropped.
#
# NOTE: This cache is per-process and non-distributed. For multi-instance
# deployments (or if you need persistence), replace with Redis or similar.
CACHE_ENABLED=true
CACHE_MAX_ITEMS=50
CACHE_TTL_MS=900000   # 15 minutes


# --- PROVIDER NOTES (FYI) ---------------------------------------------------
# OpenAI usage does NOT read from env here. The client passes the key at
# request-time via the `X-API-Key` header; the server forwards it to the
# provider (see sentiment/OpenAIProvider). Keep keys client-side/configured in
# your secret store—don’t hardcode them in this file.
#
# Ollama (local LLaMA3) defaults to http://localhost:11434 and needs no env.
# You can override host/model when constructing the provider if desired.
